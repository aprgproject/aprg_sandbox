
Dynamic programming is a technique that combines the correctness of complete search and the efficiency of greedy algorithms. 
Dynamic programming can be applied if the problem can be divided into overlapping subproblems that can be solved independently.
There are two uses for dynamic programming:
-> Finding an optimal solution: We want to find a solution that is as large as possible or as small as possible.
-> Counting the number of solutions: We want to calculate the total number of possible solutions.

We will first see how dynamic programming can be used to find an optimal solution, and then we will use the same idea for counting the solutions.
Understanding dynamic programming is a milestone in every competitive programmerâ€™s career. 
While the basic idea is simple, the challenge is how to apply dynamic programming to different problems. 

The dynamic programming algorithm is based on a recursive function that goes through all possibilities how to form the sum, like a brute force algorithm. 
However, the dynamic programming algorithm is efficient because it uses memoization and calculates the answer to each subproblem only once.

The idea of dynamic programming is to use memoization to efficiently calculate values of a recursive function. 
This means that the values of the function are stored in an array after calculating them. 
For each parameter, the value of the function is calculated recursively only once, and after this, the value can be directly retrieved from the array.



Dynamic Programming is an algorithmic paradigm that solves a given complex problem by breaking it into subproblems and stores the results of subproblems to avoid computing the same results again. 
Following are the two main properties of a problem that suggests that the given problem can be solved using Dynamic programming.
1) Overlapping Subproblems 
2) Optimal Substructure